import numpy as np
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt

# Generate synthetic data
np.random.seed(42)
observed_data = np.concatenate([np.random.normal(-5, 1, 300), np.random.normal(5, 1, 300)]).reshape(-1, 1)

# Fit GMM and get parameters
gmm = GaussianMixture(n_components=2, random_state=42).fit(observed_data)
means, covariances, weights = gmm.means_, gmm.covariances_, gmm.weights_

# Predict latent variables
latent_variable = gmm.predict(observed_data)

# Plot observed data and estimated GMM distribution
x = np.linspace(-10, 10, 1000).reshape(-1, 1)
plt.figure(figsize=(10, 6))
plt.hist(observed_data, bins=30, density=True, alpha=0.5, label='Observed Data')
plt.plot(x, np.exp(gmm.score_samples(x)), 'g-', label='Estimated Distribution (GMM)')
plt.title('EM Algorithm for Gaussian Mixture Model')
plt.xlabel('Value')
plt.ylabel('Probability Density')
plt.legend()
plt.show()
